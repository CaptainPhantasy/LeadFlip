# Fly.io configuration for LeadFlip BullMQ Worker
# Deploy with: fly deploy -c fly.worker.toml

app = "leadflip-worker"
primary_region = "iad" # US East (closest to Twilio + OpenAI)

[build]
  dockerfile = "Dockerfile.worker"

[env]
  NODE_ENV = "production"

# Workers don't need HTTP service (consume from queue only)
# But we keep auto_stop disabled for continuous processing
[http_service]
  auto_stop_machines = false
  auto_start_machines = true
  min_machines_running = 1

[metrics]
  port = 9091
  path = "/metrics"

[[vm]]
  cpu_kind = "shared"
  cpus = 1
  memory_mb = 512

# Auto-scaling based on queue depth
[scaling]
  min_machines = 1
  max_machines = 5

# Process check (worker should always be running)
[checks]
  [checks.worker_process]
    type = "tcp"
    interval = "60s"
    timeout = "5s"
    grace_period = "30s"
